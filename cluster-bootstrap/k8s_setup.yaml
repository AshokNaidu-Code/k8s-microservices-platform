---
# ==============================================================================
# PLAY 1: Install Common Prerequisites on ALL Nodes (Control Plane & Workers)
# ==============================================================================
- name: 01 - Install Prerequisites (Docker, Kube Tools, Configure Cgroup)
  hosts: all
  become: yes
  gather_facts: yes
  vars:
    # Set CNI network range (Calico default)
    pod_network_cidr: "10.0.0.0/16" 
  
  tasks:
    # ----------------------------------------------------------------------
    # A. CRITICAL RESILIENCE FIXES (Must run first)
    # ----------------------------------------------------------------------
    - name: 'A.0. CRITICAL WAIT: Wait for SSH Connection to be stable on all nodes (Fixes Unreachable)'
      ansible.builtin.wait_for_connection:
        timeout: 300

    - name: Set SSH extra args for resiliency
      set_fact:
        ansible_ssh_extra_args: "-o StrictHostKeyChecking=no -o ServerAliveInterval=50 -o ServerAliveCountMax=10"
        
    - name: A.1. CRITICAL FIX - Ensure DNS is working by using Google Public DNS
      ansible.builtin.blockinfile:
        path: /etc/resolv.conf
        block: |
          nameserver 8.8.8.8
          nameserver 8.8.4.4
        create: yes
        marker: "# {mark} ANSIBLE MANAGED BLOCK - CRITICAL DNS FIX"
      when: inventory_hostname in groups['control_plane'] or inventory_hostname in groups['workers']

    - name: A.2. Update apt cache
      ansible.builtin.apt:
        update_cache: yes
        cache_valid_time: 3600
        
    - name: A.3. CRITICAL FIX - Ensure UFW (Uncomplicated Firewall) is disabled
      ansible.builtin.systemd:
        name: ufw
        state: stopped
        enabled: false
      ignore_errors: true # Continue even if UFW isn't installed

    # ----------------------------------------------------------------------
    # B. Install Container Runtime, Kube Tools, and PIP
    # ----------------------------------------------------------------------
    - name: B1. Install Docker, containerd, Runc, and python3-pip
      ansible.builtin.apt:
        name: 
          - docker.io
          - containerd
          - runc
          - apt-transport-https
          - ca-certificates
          - python3-pip
        state: present

    - name: B2. Ensure Docker is running and enabled
      systemd:
        name: docker
        state: started
        enabled: yes

    # ----------------------------------------------------------------------
    # C. Install Kubernetes Repositories and Packages
    # ----------------------------------------------------------------------
    - name: C1. Ensure /etc/apt/keyrings directory exists
      ansible.builtin.file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'

    - name: C2. Download Kubernetes GPG key to localhost and de-armor it
      ansible.builtin.shell: |
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | gpg --dearmor -o /tmp/kubernetes-apt-keyring.gpg
      delegate_to: localhost
      run_once: yes
      become: no

    - name: C3. Copy downloaded GPG key from localhost to all target hosts
      ansible.builtin.copy:
        src: /tmp/kubernetes-apt-keyring.gpg
        dest: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        remote_src: no
        mode: '0644'

    - name: C4. Add Kubernetes repository to sources list
      ansible.builtin.apt_repository:
        repo: deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /
        state: present
        update_cache: yes
        filename: kubernetes
        
    - name: C5. Install kubelet, kubeadm, and kubectl
      apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present

    - name: C6. Hold kubelet, kubeadm, and kubectl to prevent auto-updates
      ansible.builtin.dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - kubelet
        - kubeadm
        - kubectl

    # ----------------------------------------------------------------------
    # D. Configure Containerd and System Prerequisites
    # ----------------------------------------------------------------------
    - name: D0. CRITICAL FIX Disable and remove all swap (Required by Kubelet)
      ansible.builtin.shell: |
        swapoff -a
        sed -i '/\sswap\s/ s/^\(.*\)$/#\1/g' /etc/fstab
      changed_when: true

    - name: D1. Ensure Kubernetes prerequisites are met
      copy:
        content: |
          net.bridge.bridge-nf-call-iptables = 1
          net.ipv4.ip_forward = 1
        dest: /etc/sysctl.d/99-kubernetes-cri.conf
        mode: '0644'

    - name: D.2. Load br_netfilter and overlay modules
      community.general.modprobe:
        name: "{{ item }}"
        state: present
      with_items:
        - br_netfilter
        - overlay

    - name: D3. Apply sysctl parameters
      sysctl:
        name: "{{ item }}"
        value: '1'
        state: present
        reload: yes
      with_items:
        - net.bridge.bridge-nf-call-iptables
        - net.bridge.bridge-nf-call-ip6tables
        - net.ipv4.ip_forward

    - name: D4. Configure docker cgroup driver to systemd
      ansible.builtin.copy:
        content: |
          {
            "exec-opts": ["native.cgroupdriver=systemd"],
            "log-driver": "json-file",
            "log-opts": {
              "max-size": "100m"
            },
            "storage-driver": "overlay2"
          }
        dest: /etc/docker/daemon.json
        mode: '0644'
      notify: Restart docker

    - name: D5. Enable and restart kubelet to apply cgroup driver
      ansible.builtin.systemd:
        name: kubelet
        state: restarted
        enabled: yes

  handlers:
    - name: Restart docker
      ansible.builtin.systemd:
        name: docker
        state: restarted

# ==============================================================================
# PLAY 2: Initialize Control Plane Node
# ==============================================================================
- name: 02 - Initialize Control Plane
  hosts: control_plane
  gather_facts: yes
  become: yes
  vars:
    pod_network_cidr: "10.0.0.0/16" 
  
  tasks:
    # ----------------------------------------------------------------------
    # A. Kubeadm Init & Setup
    # ----------------------------------------------------------------------
    - name: A0.85. CRITICAL - Stop kubelet service
      ansible.builtin.systemd:
        name: kubelet
        state: stopped
      when: inventory_hostname in groups['control_plane']
      ignore_errors: yes

    - name: A0.9. CRITICAL RESET - Deep clean Kubernetes directories
      ansible.builtin.shell: |
        set -e
        systemctl stop kubelet || true
        sleep 3
        rm -rf /etc/kubernetes/
        rm -rf /var/lib/etcd/
        rm -rf /var/lib/kubelet/
        rm -rf /etc/cni/net.d/
        rm -rf /var/run/kubernetes/
        mkdir -p /etc/kubernetes/
        echo "Cleanup complete"
      when: inventory_hostname in groups['control_plane']
      ignore_errors: yes
      register: cleanup_result

    - name: A0.95. CRITICAL RESET - Full kubeadm reset
      ansible.builtin.shell: |
        set -e
        kubeadm reset -f --ignore-preflight-errors=all || true
        sleep 5
      when: inventory_hostname in groups['control_plane']
      ignore_errors: yes
      register: reset_result

    - name: A0.99. Wait before kubeadm init
      ansible.builtin.pause:
        sleep 10
      when: inventory_hostname in groups['control_plane']

    - name: A1. Run kubeadm init on the control plane
      ansible.builtin.shell: |
        PUBLIC_IP=$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4)
        echo "Control Plane IP: {{ ansible_default_ipv4.address }}"
        echo "Public IP: $PUBLIC_IP"
        kubeadm init \
          --kubernetes-version v1.29.15 \
          --pod-network-cidr=10.0.0.0/16 \
          --apiserver-advertise-address={{ ansible_default_ipv4.address }} \
          --control-plane-endpoint={{ ansible_default_ipv4.address }}:6443 \
          --apiserver-cert-extra-sans={{ ansible_default_ipv4.address }},$PUBLIC_IP \
          --cri-socket=unix:///run/containerd/containerd.sock \
          --upload-certs \
          --ignore-preflight-errors=all
        register: init_result
        when: inventory_hostname in groups['control_plane']
        retries: 2
        delay: 20
        failed_when: "init_result.rc != 0 and 'cgroup v2' not in init_result.stderr"
      
    - name: A1.5. CRITICAL INSTALL Install Python Kubernetes client
      ansible.builtin.pip:
        name: kubernetes
        state: latest
        executable: pip3
      when: init_result is success
      retries: 3
      delay: 5

    - name: A1.7. CRITICAL WAIT Wait for API Server port (6443) to open
      ansible.builtin.wait_for:
        host: "{{ ansible_default_ipv4.address }}"
        port: 6443
        delay: 5
        timeout: 120
        state: started
      when: init_result is success

    - name: A1.8. Create .kube directory for the user
      ansible.builtin.file:
        path: /home/{{ ansible_user }}/.kube
        state: directory
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0755'
      when: init_result is success

    - name: A1.9. Copy admin.conf to user's .kube directory
      ansible.builtin.copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/{{ ansible_user }}/.kube/config
        remote_src: yes
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0644'
      when: init_result is success

    - name: A1.95. CRITICAL WAIT Wait for connection to stabilize
      ansible.builtin.wait_for_connection:
        timeout: 60
      when: init_result is success
      
    # ----------------------------------------------------------------------
    # A2. Wait for API Server Pod to be ready
    # ----------------------------------------------------------------------
    - name: A2. Wait for API Server Pod to be running before CNI install
      ansible.builtin.shell: |
        kubectl get pod -n kube-system -l component=kube-apiserver -o jsonpath='{.items[0].status.containerStatuses[*].ready}' | grep -q 'true'
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: apiserver_ready_check
      until: apiserver_ready_check.rc == 0
      retries: 30
      delay: 10
      changed_when: false
      when: init_result is success

    - name: A2.5. CRITICAL WAIT - Wait for API Server to stabilize
    # Use the wait_for module to check the port on the local machine (the Control Plane)
      ansible.builtin.wait_for:
        port: 6443
        host: 127.0.0.1 # Check the local host
        state: started
        delay: 10      # Wait 10 seconds before checking
        timeout: 180   # Wait up to 3 minutes for stabilization (increase this)
        msg: "Kubernetes API server port 6443 never opened/stabilized on localhost."
      delegate_to: "{{ inventory_hostname }}"
      when: inventory_hostname in groups['control_plane']
    # ----------------------------------------------------------------------
    # C. Install CNI (Calico)
    # ----------------------------------------------------------------------
    - name: C1. Install Calico CNI
      ansible.builtin.command: >
        kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/calico.yaml
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: calico_install_output
      changed_when: true
      when: init_result is success

    # ----------------------------------------------------------------------
    # D. Retrieve Join Command for Workers
    # ----------------------------------------------------------------------
    - name: D1. Generate and store the join command for worker nodes
      ansible.builtin.shell:
        cmd: >
          kubeadm token create --print-join-command --ttl 0
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: worker_join_command
      changed_when: false
      when: init_result is success

    - name: D2. Store the join command for the next play
      ansible.builtin.set_fact:
        k8s_join_command: "{{ worker_join_command.stdout }}"
      when: init_result is success

# ==============================================================================
# PLAY 3: Join Worker Nodes to the Cluster
# ==============================================================================
- name: 03 - Join Worker Nodes
  hosts: workers
  become: yes
  tasks:
    - name: A. Wait for Control Plane to finish initialization
      ansible.builtin.wait_for_connection:
        timeout: 300

    - name: B. Reset worker node if previously configured
      ansible.builtin.command: kubeadm reset -f
      changed_when: true
      ignore_errors: yes

    - name: C. Join the cluster
      ansible.builtin.command: "{{ hostvars[groups['control_plane'][0]]['k8s_join_command'] }}"
      changed_when: true
      when: 
        - hostvars[groups['control_plane'][0]]['k8s_join_command'] is defined
