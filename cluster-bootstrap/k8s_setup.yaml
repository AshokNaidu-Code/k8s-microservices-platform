---
# ==============================================================================
# PLAY 1: Install Common Prerequisites on ALL Nodes (Control Plane & Workers)
# ==============================================================================
- name: 01 - Install Prerequisites (Docker, Kube Tools, Configure Cgroup)
  hosts: all
  become: yes
  gather_facts: yes
  vars:
    # Set CNI network range (Calico default)
    pod_network_cidr: "10.0.0.0/16" 
  
  tasks:
    # ----------------------------------------------------------------------
    # A. CRITICAL RESILIENCE FIXES (Must run first)
    # ----------------------------------------------------------------------
    - name: 'A.0. CRITICAL WAIT: Wait for SSH Connection to be stable on all nodes (Fixes Unreachable)'
      ansible.builtin.wait_for_connection:
        timeout: 300
        
    - name: A.1. CRITICAL FIX - Ensure DNS is working by using Google Public DNS
      ansible.builtin.blockinfile:
        path: /etc/resolv.conf
        block: |
          nameserver 8.8.8.8
          nameserver 8.8.4.4
        create: yes
        marker: "# {mark} ANSIBLE MANAGED BLOCK - CRITICAL DNS FIX"
      # Using 'worker_nodes' as fixed in the previous iteration
      when: inventory_hostname in groups['control_plane'] or inventory_hostname in groups['worker_nodes']

    - name: A.2. Update apt cache
      ansible.builtin.apt:
        update_cache: yes
        cache_valid_time: 3600

    # ----------------------------------------------------------------------
    # B. Install Container Runtime, Kube Tools, and PIP
    # ----------------------------------------------------------------------
    - name: B1. Install Docker, containerd, Runc, and python3-pip
      ansible.builtin.apt:
        name: 
          - docker.io
          - containerd
          - runc
          - apt-transport-https
          - ca-certificates
          - python3-pip # Required for the kubernetes Python library
        state: present

    - name: B2. Ensure Docker is running and enabled
      systemd:
        name: docker
        state: started
        enabled: yes

    # ----------------------------------------------------------------------
    # C. Install Kubernetes Repositories and Packages (RESILIENT COPY FIX)
    # ----------------------------------------------------------------------
    - name: C1. Ensure /etc/apt/keyrings directory exists
      ansible.builtin.file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'

    - name: C2. Download Kubernetes GPG key to localhost and de-armor it
      ansible.builtin.shell: |
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | gpg --dearmor -o /tmp/kubernetes-apt-keyring.gpg
      delegate_to: localhost
      run_once: yes
      become: no

    - name: C3. Copy downloaded GPG key from localhost to all target hosts
      ansible.builtin.copy:
        src: /tmp/kubernetes-apt-keyring.gpg
        dest: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        remote_src: no # Source is on localhost
        mode: '0644'

    - name: C4. Add Kubernetes repository to sources list
      ansible.builtin.apt_repository:
        repo: deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /
        state: present
        update_cache: yes
        filename: kubernetes
        
    - name: C5. Install kubelet, kubeadm, and kubectl
      apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present

    - name: C6. Hold kubelet, kubeadm, and kubectl to prevent auto-updates
      ansible.builtin.dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - kubelet
        - kubeadm
        - kubectl

    # ----------------------------------------------------------------------
    # D. Configure Containerd to use 'systemd' Cgroup Driver
    # ----------------------------------------------------------------------
    - name: D1. Ensure Kubernetes prerequisites are met
      copy:
        content: |
          net.bridge.bridge-nf-call-iptables = 1
          net.ipv4.ip_forward = 1
        dest: /etc/sysctl.d/99-kubernetes-cri.conf
        mode: '0644'

    - name: D.2. Load br_netfilter and overlay modules
      community.general.modprobe:
        name: "{{ item }}"
        state: present
      with_items:
        - br_netfilter
        - overlay

    - name: D3. Apply sysctl parameters
      sysctl:
        name: "{{ item }}"
        value: '1'
        state: present
        reload: yes
      with_items:
        - net.bridge.bridge-nf-call-iptables
        - net.bridge.bridge-nf-call-ip6tables
        - net.ipv4.ip_forward

    - name: D4. Configure docker cgroup driver to systemd (FIXED)
      ansible.builtin.copy:
        content: |
          {
            "exec-opts": ["native.cgroupdriver=systemd"],
            "log-driver": "json-file",
            "log-opts": {
              "max-size": "100m"
            },
            "storage-driver": "overlay2"
          }
        dest: /etc/docker/daemon.json
        mode: '0644'
      notify: Restart docker

    - name: D5. Enable and restart kubelet to apply cgroup driver
      ansible.builtin.systemd:
        name: kubelet
        state: restarted
        enabled: yes
      # End of Play 1 tasks

# ==============================================================================
# HANDLERS (DEFINED ONCE AT THE END OF THE PLAYBOOK)
# ==============================================================================
  handlers:
    - name: Restart docker
      ansible.builtin.systemd:
        name: docker
        state: restarted

# ==============================================================================
# PLAY 2: Initialize Control Plane Node
# ==============================================================================
- name: 02 - Initialize Control Plane
  hosts: control_plane
  gather_facts: yes
  become: yes
  vars:
    # Set CNI network range (Calico default)
    pod_network_cidr: "10.0.0.0/16" 
  
  tasks:
    # ----------------------------------------------------------------------
    # A. Kubeadm Init & Setup
    # ----------------------------------------------------------------------
    - name: A.0. CRITICAL RESET- Reset Kubernetes cluster before init (Fixes rc=1 failure)
      ansible.builtin.command: kubeadm reset -f
      changed_when: true
      ignore_errors: yes

    - name: A1. Run kubeadm init on the control plane (FIXED- Added CRI socket for Containerd)
      ansible.builtin.shell: |
        kubeadm init \
        --pod-network-cidr={{ pod_network_cidr }} \
        --apiserver-advertise-address={{ ansible_default_ipv4.address }} \
        --control-plane-endpoint={{ ansible_default_ipv4.address }}:6443 \
        --cri-socket=/run/containerd/containerd.sock \
        --ignore-preflight-errors=all
      register: init_result
      
    - name: A1.5. CRITICAL INSTALL- Install Python Kubernetes client for k8s_info module (FIXED- PEP 668)
      ansible.builtin.pip:
        name: kubernetes
        state: present
        executable: pip3
        extra_args: --break-system-packages 
      when: init_result is success
      
    - name: A1.7. CRITICAL WAIT- Wait for API Server port (6443) to open (FIXED- Connection Refused)
      ansible.builtin.wait_for:
        host: "{{ ansible_default_ipv4.address }}"
        port: 6443
        delay: 5 # Start checking after 5 seconds
        timeout: 120 # Wait up to 2 minutes
        state: started # Wait for the port to be in a listening state
      when: init_result is success

    # ----------------------------------------------------------------------
    # A2. CRITICAL WAIT: Wait for the API server static pod to become ready
    # (Fixes Calico CNI failure)
    # ----------------------------------------------------------------------
    - name: A2. Wait for API Server Pod to be running before CNI install (FIXED- SSL Cert error)
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        namespace: kube-system
        field_selectors:
          - metadata.name=kube-apiserver
        wait: yes
        wait_timeout: 300 # Wait up to 5 minutes (300 seconds)
        wait_condition:
          type: Ready
          status: "True"
        validate_certs: no # Bypass self-signed cert verification
      become_user: "{{ ansible_user }}"
      when: init_result is success

    # ----------------------------------------------------------------------
    # B. Configure Kubeconfig
    # ----------------------------------------------------------------------
    - name: B1. Create .kube directory for the user
      ansible.builtin.file:
        path: /home/{{ ansible_user }}/.kube
        state: directory
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0755'

    - name: B2. Copy admin.conf to user's .kube directory
      ansible.builtin.copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/{{ ansible_user }}/.kube/config
        remote_src: yes
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0644'

    # ----------------------------------------------------------------------
    # C. Install CNI (Calico)
    # ----------------------------------------------------------------------
    - name: C1. Install Calico CNI
      ansible.builtin.command: >
        kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/calico.yaml
      # The command must be run as the user who owns the kubeconfig
      become_user: "{{ ansible_user }}"
      register: calico_install_output
      changed_when: true

    # ----------------------------------------------------------------------
    # D. Retrieve Join Command for Workers
    # ----------------------------------------------------------------------
    - name: D1. Generate and store the join command for worker nodes
      ansible.builtin.shell:
        cmd: >
          kubeadm token create --print-join-command --ttl 0
      register: worker_join_command
      changed_when: false

    - name: D2. Store the join command securely for the next play
      ansible.builtin.set_fact:
        k8s_join_command: "{{ worker_join_command.stdout }}"

# ==============================================================================
# PLAY 3: Join Worker Nodes to the Cluster
# ==============================================================================
- name: 03 - Join Worker Nodes
  hosts: worker_nodes
  become: yes
  tasks:
    - name: A. Wait for Control Plane to finish initialization
      ansible.builtin.wait_for_connection:
        timeout: 300

    - name: B. Join the cluster
      ansible.builtin.command: "{{ hostvars[groups['control_plane'][0]]['k8s_join_command'] }}"
      changed_when: true
      when: 
        # Only run if the join command was successfully generated
        - hostvars[groups['control_plane'][0]]['k8s_join_command'] is defined
